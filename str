her is the structure of the project directory for the Resume Optimization Crew project. This structure is designed to keep the code organized and maintainable, while also providing a clear separation between different components of the project.
resume-optimization-crew/
│
├── .env                          # Environment variables (API keys)
├── .gitignore                    # Git ignore file
├── pyproject.toml                # Python project configuration
├── README.md                     # Project documentation
├── uv.lock                       # Dependency lock file
│
├── docs/                         # Documentation files
│
├── knowledge/                    # Storage for uploaded resumes
│   └── Ennajari.pdf              # Sample resume
│
├── output/                       # Output directory for generated files
│   ├── company_research.json
│   ├── final_report.md
│   ├── job_analysis.json
│   ├── optimized_resume.md
│   └── resume_optimization.json
│
└── src/                          # Source code
    │
    └── resume_crew/              # Main package
        ├── __init__.py
        ├── crew.py                # CrewAI implementation
        ├── main.py                # Entry point
        ├── models.py              # Data models
        │
        ├── config/                # Configuration files
        │   ├── agents.yaml        # Agent definitions
        │   └── tasks.yaml         # Task definitions
        │
        └── tools/                 # Custom tools
            ├── __init__.py
            └── custom_tool.py     # Resume parser tool
and her is the code of all file :
# .env
MODEL=gemini/gemini-1.5-flash
GEMINI_API_KEY=AIzaSyAczCyyNGdK7xsBSu2itvilLGMtn6d0QiY
SERPER_API_KEY=57fe6a9900168364214360f6d1165eee159c8717
CREWAI_TELEMETRY_DISABLED=true
├── crew.py 
import os
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool, ScrapeWebsiteTool
from pathlib import Path
import yaml
from typing import Dict, Any
from .tools.custom_tool import ResumeParserTool

@CrewBase
class ResumeCrew:
    """ResumeCrew for resume optimization and interview preparation"""

    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    def __init__(self, resume_path=None) -> None:
        """Initialize the crew with configurations"""
        self.base_dir = Path(__file__).parent.parent.parent
        self.knowledge_dir = self.base_dir / "knowledge"
        
        # Use provided resume path or default
        if resume_path:
            self.resume_path = str(resume_path)
        else:
            self.resume_path = str(self.knowledge_dir / "current_resume.pdf")
        
        agents_path = Path(__file__).parent / self.agents_config
        with open(agents_path, 'r') as f:
            self.agents_yaml = yaml.safe_load(f)
            
        tasks_path = Path(__file__).parent / self.tasks_config
        with open(tasks_path, 'r') as f:
            self.tasks_yaml = yaml.safe_load(f)
    
    def set_resume_path(self, resume_path):
        """Update the resume path"""
        self.resume_path = str(resume_path)

    def _create_task_config(self, task_name: str) -> Dict[str, Any]:
        """Helper method to convert task YAML to proper dict config"""
        task_data = self.tasks_yaml[task_name]
        return {
            "description": task_data.get("description", "").format(
                resume_path=self.resume_path,
                job_url="{job_url}",
                company_name="{company_name}"
            ),
            "expected_output": task_data.get("expected_output", ""),
            "agent": task_data.get("agent", None),
            "context": task_data.get("context", [])
        }

    @agent
    def resume_analyzer(self) -> Agent:
        return Agent(
            role=self.agents_yaml['resume_analyzer']['role'],
            goal=self.agents_yaml['resume_analyzer']['goal'],
            backstory=self.agents_yaml['resume_analyzer']['backstory'],
            verbose=True,
            tools=[ResumeParserTool()],
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )
    
    
    @agent
    def job_analyzer(self) -> Agent:
        return Agent(
            role=self.agents_yaml['job_analyzer']['role'],
            goal=self.agents_yaml['job_analyzer']['goal'],
            backstory=self.agents_yaml['job_analyzer']['backstory'] + " If a URL cannot be accessed directly, uses search capabilities to find information about the job role and company requirements.",
            verbose=True,
            tools=[ScrapeWebsiteTool(), SerperDevTool(), ResumeParserTool()],
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )

    @agent
    def company_researcher(self) -> Agent:
        return Agent(
            role=self.agents_yaml['company_researcher']['role'],
            goal=self.agents_yaml['company_researcher']['goal'],
            backstory=self.agents_yaml['company_researcher']['backstory'],
            verbose=True,
            tools=[SerperDevTool()],
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )

    @agent
    def resume_writer(self) -> Agent:
        return Agent(
            role=self.agents_yaml['resume_writer']['role'],
            goal=self.agents_yaml['resume_writer']['goal'],
            backstory=self.agents_yaml['resume_writer']['backstory'],
            verbose=True,
            tools=[ResumeParserTool()],
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )

    @agent
    def report_generator(self) -> Agent:
        return Agent(
            role=self.agents_yaml['report_generator']['role'],
            goal=self.agents_yaml['report_generator']['goal'],
            backstory=self.agents_yaml['report_generator']['backstory'],
            verbose=True,
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )
    @agent
    def cover_letter_writer(self) -> Agent:
        return Agent(
            role=self.agents_yaml['cover_letter_writer']['role'],
            goal=self.agents_yaml['cover_letter_writer']['goal'],
            backstory=self.agents_yaml['cover_letter_writer']['backstory'],
            verbose=True,
            tools=[ResumeParserTool(), SerperDevTool()],
            llm=LLM(
                model="gemini/gemini-1.5-flash",
                api_key=os.getenv("GEMINI_API_KEY")
            )
        )

    @task
    def generate_cover_letter_task(self) -> Task:
        task_config = self._create_task_config('generate_cover_letter_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.cover_letter_writer(),
            context=[
                self.analyze_job_task(), 
                self.optimize_resume_task(), 
                self.research_company_task()
            ],
            output_file='output/cover_letter.json'
        )
    @task
    def analyze_job_task(self) -> Task:
        task_config = self._create_task_config('analyze_job_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.job_analyzer(),
            output_file='output/job_analysis.json'
        )

    @task
    def optimize_resume_task(self) -> Task:
        task_config = self._create_task_config('optimize_resume_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.resume_analyzer(),
            context=[self.analyze_job_task()],
            output_file='output/resume_optimization.json'
        )

    @task
    def research_company_task(self) -> Task:
        task_config = self._create_task_config('research_company_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.company_researcher(),
            context=[self.analyze_job_task(), self.optimize_resume_task()],
            output_file='output/company_research.json'
        )

    @task
    def generate_resume_task(self) -> Task:
        task_config = self._create_task_config('generate_resume_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.resume_writer(),
            context=[self.optimize_resume_task(), self.analyze_job_task(), self.research_company_task()],
            output_file='output/optimized_resume.md'
        )

    @task
    def generate_report_task(self) -> Task:
        task_config = self._create_task_config('generate_report_task')
        return Task(
            description=task_config["description"],
            expected_output=task_config["expected_output"],
            agent=self.report_generator(),
            context=[self.analyze_job_task(), self.optimize_resume_task(), self.research_company_task()],
            output_file='output/final_report.md'
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=[
                self.resume_analyzer(),
                self.job_analyzer(),
                self.company_researcher(),
                self.resume_writer(),
                self.report_generator(),
                self.cover_letter_writer()
            ],
            tasks=[
                self.analyze_job_task(),
                self.optimize_resume_task(),
                self.research_company_task(),
                self.generate_resume_task(),
                self.generate_report_task(),
                self.generate_cover_letter_task()
            ],
            verbose=True,
            process=Process.sequential
        )
├── main.py 
  import sys
import os
import warnings
from pathlib import Path
from .crew import ResumeCrew  # Changed from resume_crew.crew to .crew
from dotenv import load_dotenv
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))

# Load environment variables _file__
load_dotenv()

# Silence SyntaxWarning from pysbd
warnings.filterwarnings("ignore", category=SyntaxWarning, module="pysbd")

def run():
    """
    Run the resume optimization crew for McKinsey & Company.
    """
    if not os.getenv("GEMINI_API_KEY"):
        print("Error: GEMINI_API_KEY not found in environment variables.")
        sys.exit(1)
        
    output_dir = Path(__file__).parent.parent.parent / "output"
    output_dir.mkdir(exist_ok=True)
    
    inputs = {
        'job_url': 'https://www.mckinsey.com/careers/search-jobs',
        'company_name': 'McKinsey & Company',
        'resume_path': str(Path(__file__).parent.parent.parent / "knowledge" / "Ennajari.pdf")
    }
    
    print(f"Starting resume optimization with inputs: {inputs}")
    
    try:
        ResumeCrew().crew().kickoff(inputs=inputs)
        print("Resume optimization completed successfully!")
    except Exception as e:
        print(f"Error occurred: {e}")
        raise

def train():
    print("Training not implemented.")

def replay():
    print("Replay not implemented.")

def test():
    print("Testing not implemented.")

if __name__ == "__main__":
    run()             
├── models.py 
   from typing import List, Dict, Optional
from pydantic import BaseModel, Field

class SkillScore(BaseModel):
    skill_name: str = Field(description="Name of the skill being scored")
    required: bool = Field(description="Whether this skill is required or nice-to-have")
    match_level: float = Field(description="How well the candidate's experience matches (0-1)", ge=0, le=1)
    years_experience: Optional[float] = Field(description="Years of experience with this skill", default=None)
    context_score: float = Field(
        description="Relevance of skill usage to job requirements", ge=0, le=1, default=0.5
    )

class JobMatchScore(BaseModel):
    overall_match: float = Field(description="Overall match percentage (0-100)", ge=0, le=100)
    technical_skills_match: float = Field(description="Technical skills match percentage", ge=0, le=100)
    soft_skills_match: float = Field(description="Soft skills match percentage", ge=0, le=100)
    experience_match: float = Field(description="Experience level match percentage", ge=0, le=100)
    education_match: float = Field(description="Education requirements match percentage", ge=0, le=100)
    industry_match: float = Field(description="Industry experience match percentage", ge=0, le=100)
    skill_details: List[SkillScore] = Field(description="Detailed scoring for each skill", default_factory=list)
    strengths: List[str] = Field(description="Candidate strengths", default_factory=list)
    gaps: List[str] = Field(description="Areas needing improvement", default_factory=list)
    scoring_factors: Dict[str, float] = Field(
        description="Weights for scoring components",
        default_factory=lambda: {
            "technical_skills": 0.35,
            "soft_skills": 0.20,
            "experience": 0.25,
            "education": 0.10,
            "industry": 0.10
        }
    )

class JobRequirements(BaseModel):
    technical_skills: List[str] = Field(description="Required technical skills", default_factory=list)
    soft_skills: List[str] = Field(description="Required soft skills", default_factory=list)
    experience_requirements: List[str] = Field(description="Experience requirements", default_factory=list)
    key_responsibilities: List[str] = Field(description="Key job responsibilities", default_factory=list)
    education_requirements: List[str] = Field(description="Education requirements", default_factory=list)
    nice_to_have: List[str] = Field(description="Preferred skills", default_factory=list)
    job_title: str = Field(description="Job title", default="")
    department: Optional[str] = Field(description="Department or team", default=None)
    job_level: Optional[str] = Field(description="Position level", default=None)
    location_requirements: Dict[str, str] = Field(description="Location details", default_factory=dict)
    compensation: Dict[str, str] = Field(description="Compensation details", default_factory=dict)
    benefits: List[str] = Field(description="Benefits and perks", default_factory=list)
    tools_and_technologies: List[str] = Field(description="Tools/technologies used", default_factory=list)
    industry_knowledge: List[str] = Field(description="Industry-specific knowledge", default_factory=list)
    certifications_required: List[str] = Field(description="Required certifications", default_factory=list)
    job_url: str = Field(description="Job posting URL", default="")
    match_score: JobMatchScore = Field(description="Candidate match scoring")
    score_explanation: List[str] = Field(description="Scoring explanation", default_factory=list)

class ResumeOptimization(BaseModel):
    content_suggestions: List[Dict[str, str]] = Field(description="Content optimization suggestions", default_factory=list)
    skills_to_highlight: List[str] = Field(description="Skills to emphasize", default_factory=list)
    achievements_to_add: List[str] = Field(description="Achievements to add/modify", default_factory=list)
    keywords_for_ats: List[str] = Field(description="ATS keywords", default_factory=list)
    formatting_suggestions: List[str] = Field(description="Formatting improvements", default_factory=list)

class CompanyResearch(BaseModel):
    recent_developments: List[str] = Field(description="Recent company news", default_factory=list)
    culture_and_values: List[str] = Field(description="Company culture and values", default_factory=list)
    market_position: Dict[str, List[str]] = Field(description="Market position and competitors", default_factory=dict)
    growth_trajectory: List[str] = Field(description="Company growth plans", default_factory=list)
    interview_questions: List[str] = Field(description="Strategic interview questions", default_factory=list)
    
    # Model method to convert to valid JSON
    def json(self, **kwargs):
        return super().model_dump_json(**kwargs)

class CoverLetter(BaseModel):
    """Model for generating a comprehensive cover letter"""
    opening_paragraph: str = Field(description="Engaging opening paragraph", default="")
    experience_paragraphs: List[str] = Field(description="Paragraphs highlighting relevant experience", default_factory=list)
    company_alignment_paragraph: str = Field(description="Paragraph showing alignment with company values", default="")
    closing_paragraph: str = Field(description="Strong closing paragraph with call to action", default="")
    tone: str = Field(description="Tone of the cover letter", default="professional")
    personalization_score: float = Field(description="How well the letter is personalized", ge=0, le=1, default=0.5)
    key_achievements: List[str] = Field(description="Key achievements highlighted", default_factory=list)
    
    def json(self, **kwargs):
        return super().model_dump_json(**kwargs)
└── tasks.yaml                 
├── agents.yaml       
 resume_analyzer:
  role: "Resume Optimization Expert"
  goal: "Analyze resumes and provide structured optimization suggestions"
  backstory: >
    A resume optimization specialist with expertise in ATS systems and modern resume best practices. Excels at analyzing PDF resumes and providing actionable, ATS-compatible suggestions.

job_analyzer:
  role: "Job Requirements Analyst"
  goal: "Analyze job descriptions and score candidate fit"
  backstory: >
    An expert in job market analysis and candidate evaluation. Breaks down job requirements into clear categories and scores candidate qualifications accurately, considering technical and soft skills.

company_researcher:
  role: "Company Intelligence Specialist"
  goal: "Research companies and prepare interview insights"
  backstory: >
    A corporate research expert who gathers and synthesizes the latest company data to create comprehensive profiles and prepare candidates for interviews.

resume_writer:
  role: "Resume Markdown Specialist"
  goal: "Create beautifully formatted, ATS-optimized resumes in markdown"
  backstory: >
    A resume writing expert specializing in markdown-formatted, ATS-friendly resumes that showcase candidate strengths professionally.

report_generator:
  role: "Career Report Generator and Markdown Specialist"
  goal: "Create comprehensive, visually appealing, actionable reports from job application analysis"
  backstory: >
    An expert in data visualization and technical writing, transforming structured analysis into clear, actionable markdown reports with proper formatting and visual elements.

cover_letter_writer:
    role: "Strategic Cover Letter Specialist"
    goal: >
      Craft real-world, personalized cover letters in fluent professional English that highlight the candidate's unique value proposition and align with the target job.
    backstory: >
      An experienced career communication expert with a background in human resources and executive recruitment.
      Specializes in transforming resumes and job descriptions into compelling one-page cover letters that meet formal standards used by hiring professionals.
      Fluent in translating career paths into concise, high-impact narratives without using artificial metrics or scoring systems.
    style_guidelines:
      - Always use formal and professional tone
      - Structure letters with a standard heading, introduction, body, and conclusion
      - Avoid bullet points, technical jargon, or informal phrasing
      - Keep to ~300–400 words (one page)
      - Do not include any "Personalization Score", JSON structure, or metadata
      - Adapt to the job title and company using natural, contextual references
ustom_tool.py   
from crewai.tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field
import pdfplumber
from pathlib import Path

class ResumeParserInput(BaseModel):
    """Input schema for ResumeParserTool."""
    resume_path: str = Field(..., description="Path to the resume PDF file.")

class ResumeParserTool(BaseTool):
    name: str = "ResumeParserTool"
    description: str = (
        "Extracts text content from a PDF resume file for further processing."
    )
    args_schema: Type[BaseModel] = ResumeParserInput

    def _run(self, resume_path: str) -> str:
        try:
            resume_path = Path(resume_path)
            if not resume_path.exists():
                return f"Error: Resume file not found at {resume_path}"
            with pdfplumber.open(resume_path) as pdf:
                text = ""
                for page in pdf.pages:
                    text += page.extract_text() or ""
                if not text.strip():
                    return "Error: No text extracted from resume PDF"
                return text
        except Exception as e:
            return f"Error processing resume: {str(e)}"

app.py:
import streamlit as st
import os
import sys
import json
import tempfile
import shutil
import re
from pathlib import Path
from dotenv import load_dotenv

# Add src directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
src_dir = os.path.join(current_dir, "src")
sys.path.append(current_dir)

# Import crew after adding to path
from src.resume_crew.crew import ResumeCrew

# Load environment variables
load_dotenv()

# Create output directory if it doesn't exist
output_dir = Path(current_dir) / "output"
output_dir.mkdir(exist_ok=True)

st.set_page_config(
    page_title="Resume Optimization Crew",
    page_icon="📝",
    layout="wide"
)

def extract_json_from_content(content):
    """Extract JSON content from LLM response that might contain markdown codeblocks"""
    # Try to extract JSON from markdown code blocks
    json_pattern = r"```(?:json)?\s*([\s\S]*?)```"
    matches = re.findall(json_pattern, content)
    
    if matches:
        for match in matches:
            try:
                return json.loads(match.strip())
            except json.JSONDecodeError:
                continue
    
    # If no valid JSON in code blocks, try parsing the whole content
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        # As a last resort, try to clean the content
        # Remove any non-JSON content at beginning/end
        clean_content = re.sub(r'^[^{]*', '', content)
        clean_content = re.sub(r'[^}]*$', '', clean_content)
        try:
            return json.loads(clean_content)
        except json.JSONDecodeError:
            return None

def display_markdown_file(file_path):
    """Display markdown file content"""
    try:
        if not os.path.exists(file_path):
            st.warning(f"File not found: {file_path}")
            return
            
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            st.markdown(content)
    except Exception as e:
        st.error(f"Error reading file: {e}")
        st.error(f"File path: {file_path}")

def display_json_file(file_path, title):
    """Display JSON file content in an expandable section"""
    try:
        if not os.path.exists(file_path):
            st.warning(f"File not found: {file_path}")
            return
            
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            try:
                # Try standard JSON parsing first
                data = json.loads(content)
                with st.expander(title):
                    st.json(data)
            except json.JSONDecodeError:
                # If that fails, try to extract JSON from LLM response
                data = extract_json_from_content(content)
                if data:
                    with st.expander(title):
                        st.json(data)
                else:
                    with st.expander(title):
                        st.error("Invalid JSON format in the file")
                        st.text(content[:500] + "..." if len(content) > 500 else content)
    except Exception as e:
        st.error(f"Error reading JSON file: {e}")
        st.error(f"File path: {file_path}")

def process_json_output(file_path):
    """Process JSON output files to ensure valid JSON"""
    try:
        if not os.path.exists(file_path):
            return False
            
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Try to extract valid JSON
        data = extract_json_from_content(content)
        
        if data:
            # Write back valid JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2)
            return True
        return False
    except Exception as e:
        print(f"Error processing JSON file {file_path}: {e}")
        return False

def format_cover_letter_from_json(data):
    """Format cover letter JSON into a readable markdown text with improved error handling"""
    if not data or not isinstance(data, dict):
        return "No cover letter data found."
    
    # Construct markdown-formatted cover letter
    cover_letter = ""
    
    # Add opening paragraph
    if data.get('opening_paragraph'):
        cover_letter += f"{data['opening_paragraph']}\n\n"
    
    # Add experience paragraphs
    if data.get('experience_paragraphs'):
        # Ensure experience_paragraphs is a list
        experience_paragraphs = data['experience_paragraphs'] if isinstance(data['experience_paragraphs'], list) else [data['experience_paragraphs']]
        for paragraph in experience_paragraphs:
            cover_letter += f"{paragraph}\n\n"
    
    # Add company alignment paragraph
    if data.get('company_alignment_paragraph'):
        cover_letter += f"{data['company_alignment_paragraph']}\n\n"
    
    # Add closing paragraph
    if data.get('closing_paragraph'):
        cover_letter += f"{data['closing_paragraph']}\n\n"
    
    # Safely handle personalization score
    personalization_score = data.get('personalization_score', 0.5)
    # Ensure personalization_score is a number (int or float)
    try:
        personalization_score = float(personalization_score)
    except (TypeError, ValueError):
        personalization_score = 0.5
    
    cover_letter += f"**Personalization Score:** {personalization_score * 100:.0f}%\n\n"
    
    # Add key achievements
    if data.get('key_achievements'):
        # Ensure key_achievements is a list
        achievements = data['key_achievements'] if isinstance(data['key_achievements'], list) else [data['key_achievements']]
        
        cover_letter += "**Key Achievements Highlighted:**\n"
        for achievement in achievements:
            cover_letter += f"- {achievement}\n"
    
    return cover_letter

def run_resume_crew(resume_path, job_url, company_name):
    """Run the resume optimization crew process"""
    # Create output directory if it doesn't exist
    output_dir = Path(current_dir) / "output"
    output_dir.mkdir(exist_ok=True)
    
    # Create a knowledge directory if it doesn't exist
    knowledge_dir = Path(current_dir) / "knowledge"
    knowledge_dir.mkdir(exist_ok=True)
    
    # Copy the resume to the knowledge directory with a fixed name
    resume_filename = "current_resume.pdf"
    resume_knowledge_path = knowledge_dir / resume_filename
    
    try:
        shutil.copy2(resume_path, resume_knowledge_path)
        st.info(f"Resume copied to knowledge directory: {resume_knowledge_path}")
    except Exception as e:
        st.error(f"Error copying resume: {str(e)}")
        return False
    
    # Create a ResumeCrew instance with the uploaded resume
    resume_crew = ResumeCrew()
    # Update the resume path
    resume_crew.resume_path = str(resume_knowledge_path)
    
    # Run the crew with the provided inputs
    inputs = {
        'job_url': job_url,
        'company_name': company_name,
        'resume_path': str(resume_knowledge_path)
    }
    
    with st.spinner("Processing your resume... This might take a few minutes"):
        try:
            # Define output file paths
            job_analysis_path = output_dir / "job_analysis.json"
            resume_optimization_path = output_dir / "resume_optimization.json"
            company_research_path = output_dir / "company_research.json"
            optimized_resume_path = output_dir / "optimized_resume.md"
            final_report_path = output_dir / "final_report.md"
            cover_letter_path = output_dir / "cover_letter.json"
            
            # Run the crew
            resume_crew.crew().kickoff(inputs=inputs)
            
            # Process JSON outputs to ensure valid JSON
            json_files = [job_analysis_path, resume_optimization_path, company_research_path, cover_letter_path]
            for file_path in json_files:
                process_json_output(file_path)
            
            # Verify outputs exist
            output_files = [job_analysis_path, resume_optimization_path, company_research_path, 
                            optimized_resume_path, final_report_path, cover_letter_path]
            missing_files = [f for f in output_files if not f.exists()]
            
            if missing_files:
                st.warning(f"Some output files are missing: {[f.name for f in missing_files]}")
            
            st.success("Resume optimization completed successfully!")
            return True
        except Exception as e:
            st.error(f"Error occurred: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
            return False

def main():
    st.title("Resume Optimization Crew")
    st.write("Upload your resume, enter a job URL, and company name to optimize your resume.")
    
    # Check for API keys
    if not os.getenv("GEMINI_API_KEY"):
        st.error("Error: GEMINI_API_KEY not found in environment variables.")
        st.info("Please add your Gemini API key to the .env file.")
        return
    
    # File uploader for resume
    uploaded_file = st.file_uploader("Upload your resume (PDF)", type=["pdf"])
    
    job_url = st.text_input("Job URL", placeholder="https://example.com/jobs/position")
    company_name = st.text_input("Company Name", placeholder="Company Inc.")
    
    submit_button = st.button("Optimize Resume")
    
    if submit_button and uploaded_file and job_url and company_name:
        # Save the uploaded file to a temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            resume_path = Path(tmp_file.name)
        
        # Run the resume crew
        success = run_resume_crew(resume_path, job_url, company_name)
        
        # Clean up the temporary file after copying
        try:
            os.unlink(resume_path)
        except Exception as e:
            st.warning(f"Could not remove temporary file: {e}")
            
        if success:
            # Create paths for output files
            optimized_resume_path = os.path.join(current_dir, "output", "optimized_resume.md")
            final_report_path = os.path.join(current_dir, "output", "final_report.md")
            job_analysis_path = os.path.join(current_dir, "output", "job_analysis.json")
            resume_optimization_path = os.path.join(current_dir, "output", "resume_optimization.json")
            company_research_path = os.path.join(current_dir, "output", "company_research.json")
            cover_letter_path = os.path.join(current_dir, "output", "cover_letter.json")
            
            # Display the results
            st.header("Results")
            
            # Display tabs for different results
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "Optimized Resume", 
                "Final Report", 
                "Job Analysis", 
                "Resume Optimization", 
                "Company Research",
                "Cover Letter"
            ])
            
            with tab1:
                display_markdown_file(optimized_resume_path)
            
            with tab2:
                display_markdown_file(final_report_path)
            
            with tab3:
                display_json_file(job_analysis_path, "Job Analysis Details")
            
            with tab4:
                display_json_file(resume_optimization_path, "Resume Optimization Details")
            
            with tab5:
                display_json_file(company_research_path, "Company Research Details")
            
            with tab6:
                # Cover Letter Display
                try:
                    with open(cover_letter_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        cover_letter_data = extract_json_from_content(content)
                        if cover_letter_data:
                            # Format and display cover letter
                            cover_letter_text = format_cover_letter_from_json(cover_letter_data)
                            st.markdown(cover_letter_text)
                        else:
                            st.warning("Unable to extract cover letter data.")
                except FileNotFoundError:
                    st.warning("Cover letter file not found.")
                except Exception as e:
                    st.error(f"Error reading cover letter: {e}")
            
            # Add download buttons for the results
            st.subheader("Download Results")
            col1, col2 = st.columns(2)
            
            try:
                # First column of download buttons
                with col1:
                    if os.path.exists(optimized_resume_path):
                        with open(optimized_resume_path, "r", encoding="utf-8") as f:
                            st.download_button(
                                label="Download Optimized Resume",
                                data=f.read(),
                                file_name="optimized_resume.md",
                                mime="text/markdown"
                            )
                    else:
                        st.warning("Optimized resume file not found")
                    
                    if os.path.exists(job_analysis_path):
                        with open(job_analysis_path, "r", encoding="utf-8") as f:
                            content = f.read()
                            # Process JSON if needed for download
                            try:
                                json_data = json.loads(content)
                                formatted_json = json.dumps(json_data, indent=2)
                                st.download_button(
                                    label="Download Job Analysis",
                                    data=formatted_json,
                                    file_name="job_analysis.json",
                                    mime="application/json"
                                )
                            except:
                                data = extract_json_from_content(content)
                                if data:
                                    formatted_json = json.dumps(data, indent=2)
                                    st.download_button(
                                        label="Download Job Analysis",
                                        data=formatted_json,
                                        file_name="job_analysis.json",
                                        mime="application/json"
                                    )
                                else:
                                    st.warning("Invalid JSON format in job analysis file")
                    else:
                        st.warning("Job analysis file not found")
                
                # Second column of download buttons
                with col2:
                    if os.path.exists(final_report_path):
                        with open(final_report_path, "r", encoding="utf-8") as f:
                            st.download_button(
                                label="Download Final Report",
                                data=f.read(),
                                file_name="final_report.md",
                                mime="text/markdown"
                            )
                    else:
                        st.warning("Final report file not found")
                    
                    if os.path.exists(company_research_path):
                        with open(company_research_path, "r", encoding="utf-8") as f:
                            content = f.read()
                            # Process JSON if needed for download
                            try:
                                json_data = json.loads(content)
                                formatted_json = json.dumps(json_data, indent=2)
                                st.download_button(
                                    label="Download Company Research",
                                    data=formatted_json,
                                    file_name="company_research.json",
                                    mime="application/json"
                                )
                            except:
                                data = extract_json_from_content(content)
                                if data:
                                    formatted_json = json.dumps(data, indent=2)
                                    st.download_button(
                                        label="Download Company Research",
                                        data=formatted_json,
                                        file_name="company_research.json",
                                        mime="application/json"
                                    )
                                else:
                                    st.warning("Invalid JSON format in company research file")
                    else:
                        st.warning("Company research file not found")

                    # Add download button for Cover Letter
                    if os.path.exists(cover_letter_path):
                        try:
                            with open(cover_letter_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                                cover_letter_data = extract_json_from_content(content)
                                if cover_letter_data:
                                    # Convert cover letter JSON to markdown for download
                                    cover_letter_markdown = format_cover_letter_from_json(cover_letter_data)
                                    st.download_button(
                                        label="Download Cover Letter",
                                        data=cover_letter_markdown,
                                        file_name="cover_letter.md",
                                        mime="text/markdown"
                                    )
                                else:
                                    st.warning("Invalid cover letter data")
                        except Exception as e:
                            st.error(f"Error processing cover letter: {e}")
                    else:
                        st.warning("Cover letter file not found")

            except Exception as e:
                st.error(f"Error with download buttons: {e}")
                import traceback
                st.error(traceback.format_exc())
    elif submit_button:
        if not uploaded_file:
            st.error("Please upload your resume.")
        if not job_url:
            st.error("Please enter a job URL.")
        if not company_name:
            st.error("Please enter a company name.")

if __name__ == "__main__":
    main()